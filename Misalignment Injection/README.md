# Misalignment Injection: Full Dataset Construction Pipeline


## ğŸ§© Step-by-Step Pipeline Overview

### 1. Generate Definitions

- **Directory**: `definition generation/`
- **Output**: `generated description/`
- **Process**: Use GPT to generate natural language definitions based on ontology axioms.


### 2. Type Classification and Splitting

- **Script**: `Type_classify.py`
- **Inputs**:
  - Generated definitions
  - Ontology axioms
  - Generated CQs
- **Output**: Dataset split by misalignment types.
- **Next Step**: Move output files to `type classification/`.


### 3. Process Each Misalignment Type

#### â¤ Type 1 & Type 2

- **Script**: `type1,2_processing.py`
- **Outputs**:
  - `Final_type1.json` â†’ move to `processed types/`
  - `processed_type2.json` â†’ move to `Type2 processing/` and process type 2 in `Type2 processing/` directory.

#### â¤ Type 3

- **Script**: `type3_processing.py`
- **Output**: `Final_type3.json` â†’ move to `processed types/`

#### â¤ Type 4

- **Script**: `type4_processing.py`
- **Output**: `Final_type4.json` â†’ move to `processed types/`


### 4. Tag Type Labels

- **Notebook**: `processed types/tagging_type.ipynb`
- **Function**: Adds misalignment type labels to each ontology term.
- **Output**: Unified data with type annotations.


### 5. Merge All Processed Data

- **Script**: `merge_data.py`
- **Outputs**:
  - `merged dataset/` â†’ Combined dataset (all types)
  - `Final dataset/` â†’ Training/test splits with metadata
  - `additional settings/Generalizability/unseen ontology/` â†’ Extra dataset for unseen ontologies setting


## ğŸ“ Key Files

```
â”œâ”€â”€ Type_classify.py               # Classify and split data by misalignment type
â”œâ”€â”€ type1,2_processing.py          # Process Type 1 and Type 2 entries
â”œâ”€â”€ type3_processing.py            # Process Type 3 entries
â”œâ”€â”€ type4_processing.py            # Process Type 4 entries
â”œâ”€â”€ merge_data.py                  # Merge all processed types and split datasets
```


## ğŸ“¦ Final Output (in `Final dataset/`)

- `train_dataset.jsonl` / `test_dataset.jsonl`: Final dataset for training and evaluation
- `*_meta.jsonl`: Metadata containing axiom info, original definitions, generated CQs, and assigned type

